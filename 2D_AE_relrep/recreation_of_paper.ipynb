{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility and consistency across runs, we will set a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "def set_random_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "set_random_seeds()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.get_device_name(0))  # Prints the GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(batch_size=64, download=True):\n",
    "    \"\"\"\n",
    "    Loads and returns MNIST train and test DataLoaders.\n",
    "    \n",
    "    Args:\n",
    "        batch_size (int): The batch size for the DataLoader.\n",
    "        download (bool): Whether to download the dataset if not found.\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, test_loader: DataLoader objects for the MNIST dataset.\n",
    "    \"\"\"\n",
    "    # Define a transform to normalize the data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    # Load the training and test datasets\n",
    "    train_dataset = datasets.MNIST(root='../datasets', train=True, transform=transform, download=download) #'..' to refer back to motherfolder\n",
    "    test_dataset = datasets.MNIST(root='../datasets', train=False, transform=transform, download=download)\n",
    "    \n",
    "    # Create DataLoaders for the datasets\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Load the MNIST data\n",
    "train_loader, test_loader = load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder with a bottleneck of size 2 that maps MNIST images to a 2D latent space.\n",
    "    Includes training, evaluation, and embedding extraction methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### NOTES ###\n",
    "    # Might have to use batchnorm to impose a structure on the latent space\n",
    "\n",
    "    def __init__(self, latent_dim=2, hidden_size=128, use_batchnorm=True):\n",
    "        super().__init__()\n",
    "        # Encoder layers\n",
    "        # 784 -> 128 -> 2\n",
    "        encoder_layers = [\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, hidden_size), # asuming size 28x28 of the images\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        if use_batchnorm:\n",
    "            encoder_layers.append(nn.Batchnorm1d(hidden_size))\n",
    "        encoder_layers.append(nn.Linear(hidden_size, latent_dim)) # the size 2 bottleneck layer\n",
    "        self.encoder = nn.Sequential(*encoder_layers) # '*' is unpacking the list into it's elements\n",
    "\n",
    "        # Decoder layers\n",
    "        # 2 -> 128 -> 784\n",
    "        decoder_layers = [\n",
    "            nn.Linear(latent_dim, hidden_size),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        if use_batchnorm:\n",
    "            decoder_layers.append(nn.Batchnorm1d(hidden_size))\n",
    "        decoder_layers.extend([\n",
    "            nn.Linear(hidden_size, 28 * 28),\n",
    "            nn.Sigmoid() # normalize outputs to [0, 1] - grayscale\n",
    "        ])\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encodes an input batch (e.g., MNIST images) into the latent space.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input images of shape [batch_size, 1, 28, 28].\n",
    "        Returns:\n",
    "            z (Tensor): Encoded latent vectors of shape [batch_size, latent_dim].\n",
    "        \"\"\"\n",
    "\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes latent vectors back to the original image space.\n",
    "        \n",
    "        Args:\n",
    "            z (Tensor): Latent vectors of shape [batch_size, latent_dim].\n",
    "        Returns:\n",
    "            x_rec (Tensor): Reconstructed images of shape [batch_size, 1, 28, 28].\n",
    "        \"\"\"\n",
    "\n",
    "        x_rec = self.decoder(z)\n",
    "        return x_rec\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Complete forward pass: encode then decode.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input images.\n",
    "        Returns:\n",
    "            reconstructed (Tensor): Reconstructed images of the same shape as x.\n",
    "        \"\"\"\n",
    "        reconstructed = self.decode(self.encode(x))\n",
    "        return reconstructed\n",
    "\n",
    "    def train_one_epoch(self, train_loader, optimizer, criterion, device='cpu'):\n",
    "        \"\"\"\n",
    "        Performs one epoch of training.\n",
    "        \n",
    "        Args:\n",
    "            train_loader (DataLoader): DataLoader for the training set.\n",
    "            optimizer (torch.optim.Optimizer): Optimizer for model parameters.\n",
    "            criterion: Loss function (e.g., MSELoss, BCELoss).\n",
    "            device (str): 'cpu' or 'cuda' device.\n",
    "        \n",
    "        Returns:\n",
    "            epoch_loss (float): Average loss across this training epoch.\n",
    "        \"\"\"\n",
    "        loss_total = 0.0\n",
    "        self.train()\n",
    "\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            # Computing loss\n",
    "            reconstructed = self.forward(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            loss_total += loss.item()\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss = loss_total / len(train_loader) # Computing average loss in epoch\n",
    "        return epoch_loss\n",
    "\n",
    "    def evaluate(self, data_loader, criterion, device='cpu'):\n",
    "        \"\"\"\n",
    "        Evaluates the autoencoder on a given dataset (test or validation).\n",
    "        \n",
    "        Args:\n",
    "            data_loader (DataLoader): DataLoader for the evaluation set.\n",
    "            criterion: Loss function for reconstruction.\n",
    "            device (str): 'cpu' or 'cuda'.\n",
    "        \n",
    "        Returns:\n",
    "            eval_loss (float): Average reconstruction loss on this dataset.\n",
    "        \"\"\"\n",
    "        self.eval() # Disable gradient computation\n",
    "\n",
    "        loss_total = 0.0\n",
    "        for x, _ in data_loader:\n",
    "            x = x.to(device)\n",
    "            # Computing loss\n",
    "            reconstructed = self.forward(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            loss_total += loss.item()\n",
    "\n",
    "        eval_loss = loss_total / len(data_loader) # Computing average evaluation loss\n",
    "        return eval_loss\n",
    "\n",
    "    def fit(self, train_loader, test_loader, num_epochs, lr=1e-3, device='cpu', verbose=True):\n",
    "        \"\"\"\n",
    "        High-level method to train the autoencoder for a given number of epochs.\n",
    "        It orchestrates optimizer setup, training loop, and evaluation per epoch.\n",
    "        \n",
    "        Args:\n",
    "            train_loader (DataLoader): DataLoader for training set.\n",
    "            test_loader (DataLoader): DataLoader for test/validation set.\n",
    "            num_epochs (int): Number of epochs.\n",
    "            lr (float): Learning rate for the optimizer.\n",
    "            device (str): 'cpu' or 'cuda'.\n",
    "            verbose (bool): Each epoch prints loss if True\n",
    "        \n",
    "        Returns:\n",
    "            train_losses (list of float): Loss for each training epoch.\n",
    "            test_losses (list of float): Loss for each test epoch.\n",
    "        \"\"\"\n",
    "        self.to(device)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        loss_function = nn.BCELoss()\n",
    "\n",
    "        train_loss_list = []\n",
    "        test_loss_list = []\n",
    "        # Fitting the model\n",
    "        for epoch in range(num_epochs):\n",
    "            # Train loss\n",
    "            train_loss = self.train_one_epoch(train_loader, optimizer, criterion=loss_function,device=device)\n",
    "            train_loss_list.append(train_loss)\n",
    "            # Test loss\n",
    "            test_loss = self.evaluate(test_loader, criterion=loss_function, device=device)\n",
    "            if verbose:\n",
    "                print(f'Epoch #{epoch}')\n",
    "                print(f'Train Loss = {train_loss:.3e} --- Test Loss = {test_loss:.3e}')\n",
    "        \n",
    "        return train_loss_list, test_loss_list\n",
    "\n",
    "    def get_latent_embeddings(self, data_loader, device='cpu'):\n",
    "        \"\"\"\n",
    "        Passes the entire dataset through the encoder to extract latent vectors.\n",
    "        \n",
    "        Args:\n",
    "            data_loader (DataLoader): DataLoader for the dataset to encode.\n",
    "            device (str): 'cpu' or 'cuda'.\n",
    "        \n",
    "        Returns:\n",
    "            embeddings (Tensor): Concatenated latent vectors of shape [N, latent_dim].\n",
    "            labels (Tensor): Corresponding labels (if available) of shape [N].\n",
    "        \"\"\"\n",
    "        \n",
    "        embeddings = []\n",
    "        labels = []\n",
    "\n",
    "        self.eval() # Disable gradient computation\n",
    "\n",
    "        for x, label in data_loader:\n",
    "            x.to(device)\n",
    "            z = self.encode(x)\n",
    "            embeddings.append(z)\n",
    "            labels.append(label)\n",
    "        \n",
    "        # Concatenate the list to tensors for consistency\n",
    "        embeddings_concat = torch.cat(embeddings, dim=0)\n",
    "        labels_concat  = torch.cat(labels, dim=0)\n",
    "\n",
    "        return embeddings_concat, labels_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_anchors(embeddings, num_anchors=10):\n",
    "    \"\"\"\n",
    "    Selects a subset of embeddings to use as 'anchors' for relative representation.\n",
    "    \n",
    "    Args:\n",
    "        embeddings (Tensor or array): Shape [N, latent_dim].\n",
    "        num_anchors (int): Number of anchors to select.\n",
    "    \n",
    "    Returns:\n",
    "        anchors: A (num_anchors, latent_dim) subset of the original embeddings.\n",
    "    \"\"\"\n",
    "    anchors_index = np.random.choice(embeddings.shape[0], size=num_anchors, replace=False)\n",
    "    anchors = embeddings[anchors_index]\n",
    "    return anchors\n",
    "\n",
    "def compute_relative_coordinates(embeddings, anchors, flatten=False):\n",
    "    \"\"\"\n",
    "    Transforms 'embeddings' into a 'relative' coordinate system based on anchors.\n",
    "    One approach could be subtracting an anchor or computing offsets.\n",
    "    \n",
    "    Args:\n",
    "        embeddings (Tensor): Shape [N, latent_dim].\n",
    "        anchors (Tensor): Shape [A, latent_dim], where A = num_anchors.\n",
    "    \n",
    "    Returns:\n",
    "        relative_embeds (Tensor): The embeddings expressed relative to the anchors.\n",
    "    \"\"\"\n",
    "    # we start off with normalizing the embeddings an the anchors\n",
    "    # this way the cosine similarity is just the dot product between the word and anchor\n",
    "    embeddings_norm = embeddings/np.linalg.norm(embeddings, axis=1)[:, np.newaxis]\n",
    "    anchors_norm = anchors/np.linalg.norm(anchors, axis=1)[:, np.newaxis]\n",
    "    reletive_reps = []\n",
    "    for embedding in embeddings_norm:\n",
    "        if flatten:\n",
    "            embedding = embedding.flatten()\n",
    "        \n",
    "        reletive_rep = np.array([np.dot(embedding, anchor) for anchor in anchors_norm])\n",
    "        reletive_reps.append(reletive_rep)\n",
    "    reletive_reps = np.array(reletive_reps)\n",
    "    return reletive_reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(num_epochs=5, batch_size=64, lr=1e-3, device='cpu', anchors_num=2):\n",
    "    \"\"\"\n",
    "    Orchestrates the autoencoder pipeline:\n",
    "      1. Load data\n",
    "      2. Initialize the autoencoder\n",
    "      3. Train and evaluate\n",
    "      4. Extract embeddings\n",
    "      5. (Optional) Select anchors, compute relative coordinates\n",
    "    \n",
    "    Args:\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        batch_size (int): DataLoader batch size.\n",
    "        lr (float): Learning rate.\n",
    "        device (str): 'cpu' or 'cuda' device.\n",
    "        latent_dim (int): Dimension of the AE's latent space (2 for easy visualization).\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained autoencoder.\n",
    "        embeddings (Tensor): Latent embeddings from the test (or train) set.\n",
    "        anchors (Tensor): (Optional) set of anchor embeddings if you implement that step here.\n",
    "    \"\"\"\n",
    "    # create the data loader\n",
    "    train_loader, test_loader = load_mnist_data()\n",
    "\n",
    "    # extact the data to select anchors\n",
    "    all_features = []\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        # Move to CPU if they are on GPU (if you're using CUDA)\n",
    "        features = features.cpu()\n",
    "        \n",
    "        all_features.append(features)\n",
    "\n",
    "    # Concatenate all batches into a single tensor\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "\n",
    "    # select anchors\n",
    "    anchors = select_anchors(all_features, num_anchors=anchors_num)\n",
    "    print(\"anchor shape is \", anchors[0].shape)\n",
    "\n",
    "    AE = Autoencoder\n",
    "    \"\"\"\n",
    "    Train the encoder\n",
    "    \"\"\"\n",
    "\n",
    "    encoded_data, encoded_anchors = AE.encode(all_features).numpy(), AE.encode(anchors).numpy()\n",
    "    rel_reps = compute_relative_coordinates(encoded_data, encoded_anchors)\n",
    "    return rel_reps\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
