{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "- It seems like greedy performs best at lower anchor numbers. Is that relevant to research into?\n",
    "\n",
    "- Why do we get worse results than random in the specific case of vit_resnet decoder and vit-small encoder, even when training anchors on either of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24/03/2025\n",
    "#### TODO:\n",
    "\n",
    "- Make P optimize over all spaces\n",
    "\n",
    "- Make scatterplot that compares P against random anchors to visualize robustness differences\n",
    "\n",
    "- Make pipeline for testing relative representations on existing classifiers on CIFAR-100 and IMAGE-NET. DONE\n",
    "\n",
    "    - Test on F1 score, smaller dataset, not softmax, eucl cos combos, optimizing over all encoders, less anchors, more anchors, more classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext found at https://fasttext.cc/docs/en/english-vectors.html, version : wiki-news-300d-1M.vec.zip\n",
    "\n",
    "word2vec found at https://www.kaggle.com/datasets/sugataghosh/google-word2vec/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests\n",
    "\n",
    "- Cosine (remember to center the data first)\n",
    "\n",
    "- MRR and Jaccard\n",
    "\n",
    "- Look at their Tests\n",
    "\n",
    "- Loss in training rel decoder\n",
    "\n",
    "- Zero-shot stitching loss\n",
    "\n",
    "- Qualitative reconstructions\n",
    "\n",
    "- MSE between relative spaces\n",
    "\n",
    "- (Word embeddings?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework for next time:\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "- Scope (ECTS etc.)\n",
    "\n",
    "- Show plots\n",
    "\n",
    "- Distance measure\n",
    "\n",
    "Timeline (P, anchors across spaces)\n",
    "\n",
    "Questions\n",
    "\n",
    "Explain our work and problems\n",
    "\n",
    "\n",
    "Comparing with their results:\n",
    "\n",
    "- Less points and compare the plots (cherry pick data hmmmmm)\n",
    "\n",
    "- Higher dim and doing PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12/02/2025\n",
    "#### **Meeting - Distance measures?**\n",
    "\n",
    "##### **Plan for next time**\n",
    "\n",
    "- Write down thoughts about the project, distance measures, P matrix, etc. (see notes below)\n",
    "\n",
    "- Look through the Overleaf for the other special course\n",
    "\n",
    "- Do explorative analysis with P matrix, noise as robustness, and using euclidian measure with BachNorm\n",
    "\n",
    "##### **Notes**\n",
    "\n",
    "- The diversity measure will be larger due to amount of points\n",
    "\n",
    "- A = X * P\n",
    "\n",
    "    - Width of P is #A, and P is picking anchors from X (only one 1 per row)\n",
    "\n",
    "    - Either softmax p (sum to 1) - Then we have linear combinations of X as anchors\n",
    "\n",
    "    - Or we take the highest value of another matrix J (sampling from J) columnwise to get P\n",
    "        - Maybe this isn't optimal as we end up optimizing only for coverage (rewrite cov and div as depending on P to see)\n",
    "\n",
    "        L1 los\n",
    "\n",
    "- Why shouldnt we want to compute iteratively?\n",
    "\n",
    "    - As long as we have a good enough first point and the #A doesnt execed #D, then it shold be ok. Make sure to place the first point properly\n",
    "\n",
    "    - However, still takes a long time computationally\n",
    "\n",
    "- Coverage vs div\n",
    "\n",
    "- How do we measure at all?\n",
    "\n",
    "    - Combining measures? Bad practice\n",
    "\n",
    "    - Robustness in loss func. noise?\n",
    "\n",
    "    - Try using L2 to find the anchors \n",
    "\n",
    "Freeze encoder, train decoder on relrep and compare loss\n",
    "\n",
    "Just use euclidian??????? (first invariance to scaling with batchnorm)\n",
    "\n",
    "nn.Parameter(Tensor) (for when finding A with P. Set of random points into nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09/02/2025\n",
    "## Homework for next time:\n",
    "\n",
    "N/A\n",
    "#### **Relreps in higher dim and streamlining code**\n",
    "\n",
    "- Experimenting with higher dimensional embeddings and how this translates visually to relative representations using PCA (and 2D anchors).\n",
    "\n",
    "- Refining the AE class and dataloader to include indexes for each image in a way where we can always match parallel points (incl. anchors) in different latent spaces trained on the same data.\n",
    "\n",
    "- Created a similarity function for quantitative similarity measures between embeddings (MRR & cosine)\n",
    "\n",
    "- Initial work on the greedy optimization function for anchors\n",
    "\n",
    "#### **Results**\n",
    "<img src=\"visualization/initial_AE_testing/embeddings.png\" alt=\"2D Latent Encodings\" width=\"85%\">\n",
    "\n",
    "\n",
    "<img src=\"visualization/initial_AE_testing/rel_reps.png\" alt=\"2D Latent Encodings\" width=\"85%\">\n",
    "\n",
    "$\\textbf{Interesting observation}$: Building on the previous hypothesis: We have confirmed (visually) that the relative representation will always be a n-dimensional hyper-sphere where n is the amount of anchors if n >= the latent embedding size.\n",
    "\n",
    "##### **Plan for next time**\n",
    "- Organize codebase\n",
    "\n",
    "- Prepare for meeting\n",
    "\n",
    "- Get similarity functions up and running\n",
    "\n",
    "- Continue work on greedy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06/02/2025\n",
    "#### **Recreating relreps paper results in 2D using MNIST**\n",
    "\n",
    "- Creating the AE class\n",
    "- Creating functions to select anchors at random and comput relative coordinates\n",
    "- Running tests and plotting\n",
    "- Making sure that we can create embeddings with new seeds while maintaining the same anchors\n",
    "\n",
    "#### Results\n",
    "<img src=\"visualization/initial_AE_testing/2D_latent_encodings.png\" alt=\"2D Latent Encodings\" width=\"100%\">\n",
    "\n",
    "first plot of relative representation. made from a 2D latent space using 2 anchors\n",
    "\n",
    "<img src=\"visualization/initial_AE_testing/first_rel_rep_plot.png\" alt=\"2D Latent Encodings\" width=\"30%\">\n",
    "\n",
    "$\\textbf{Interesting observation}$: Relative representations will always create a \"hyper-ellipse\" in some n-dimensional vector space where n is equal to the number of anchors. Because you can't change one dimension without changing the others. It is easiest to visualize in 2D, but the same rule applies for higher dimensions. Maybe this is useful somehow.\n",
    "##### **Plan for next time**\n",
    "- Try making a AE with higher dimensional output and making relative representation on that\n",
    "- Experiment with new ways of choosing anchors\n",
    "- Compare absolute and relative latent spaces between different latent spaces of MNIST\n",
    "- Experiment with high-dimensional embeddings\n",
    "    - PCA for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATE\n",
    "#### **TITLE**\n",
    "\n",
    "-\n",
    "\n",
    "#### **Results**\n",
    "<img src=\"visualization/initial_AE_testing/embeddings.png\" alt=\"2D Latent Encodings\" width=\"100%\">\n",
    "\n",
    "$\\textbf{Interesting observation}$: \n",
    "\n",
    "##### **Plan for next time**\n",
    "\n",
    "\n",
    "##### **Questions**\n",
    "\n",
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
