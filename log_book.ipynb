{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework for next time:\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06/02/2025\n",
    "#### **Recreating relreps paper results in 2D using MNIST**\n",
    "\n",
    "- Creating the AE class\n",
    "- Creating functions to select anchors at random and comput relative coordinates\n",
    "- Running tests and plotting\n",
    "- Making sure that we can create embeddings with new seeds while maintaining the same anchors\n",
    "\n",
    "#### Results\n",
    "<img src=\"experiments/initial_AE_testing/2D_latent_encodings.png\" alt=\"2D Latent Encodings\" width=\"30%\">\n",
    "\n",
    "first plot of relative representation. made from a 2D latent space using 2 anchors\n",
    "\n",
    "<img src=\"experiments/initial_AE_testing/first_rel_rep_plot.png\" alt=\"2D Latent Encodings\" width=\"30%\">\n",
    "\n",
    "$\\textbf{Interesting observation}$: Relative representations will always create a \"hyper-ellipse\" in some n-dimensional vector space where n is equal to the number of anchors. Because you can't change one dimension without changing the others. It is easiest to visualize in 2D, but the same rule applies for higher dimensions. Maybe this is useful somehow.\n",
    "##### **Plan for next time**\n",
    "- Try making a AE with higher dimensional output and making relative representation on that\n",
    "- Experiment with new ways of choosing anchors\n",
    "- Compare absolute and relative latent spaces between different latent spaces of MNIST\n",
    "- Experiment with high-dimensional embeddings\n",
    "    - PCA for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09/02/2025\n",
    "results from 10 dim latent space and 2 random anchors\n",
    "\n",
    "<img src=\"experiments\\initial_rel_reps_comparision\\encodings.png\" alt=\"2D Latent Encodings\" width=\"70%\">\n",
    "\n",
    "<img src=\"experiments\\initial_rel_reps_comparision\\rel_reps.png\" alt=\"2D Latent Encodings\" width=\"70%\">\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
