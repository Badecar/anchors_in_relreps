{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework for next time:\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09/02/2025\n",
    "#### **Relreps in higher dim and streamlining code**\n",
    "\n",
    "- Experimenting with higher dimensional embeddings and how this translates visually to relative representations using PCA (and 2D anchors).\n",
    "\n",
    "- Refining the AE class and dataloader to include indexes for each image in a way where we can always match parallel points (incl. anchors) in different latent spaces trained on the same data.\n",
    "\n",
    "- Created a similarity function for quantitative similarity measures between embeddings (MRR & cosine)\n",
    "\n",
    "- Initial work on the greedy optimization function for anchors\n",
    "\n",
    "#### **Results**\n",
    "<img src=\"experiments/initial_AE_testing/embeddings.png\" alt=\"2D Latent Encodings\" width=\"100%\">\n",
    "\n",
    "\n",
    "<img src=\"experiments/initial_AE_testing/rel_reps.png\" alt=\"2D Latent Encodings\" width=\"100%\">\n",
    "\n",
    "$\\textbf{Interesting observation}$: Building on the previous hypothesis: We have confirmed (visually) that the relative representation will always be a n-dimensional hyper-sphere where n is the amount of anchors if n >= the latent embedding size.\n",
    "\n",
    "##### **Plan for next time**\n",
    "- Organize codebase\n",
    "\n",
    "- Prepare for meeting\n",
    "\n",
    "- Get similarity functions up and running\n",
    "\n",
    "- Continue work on greedy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06/02/2025\n",
    "#### **Recreating relreps paper results in 2D using MNIST**\n",
    "\n",
    "- Creating the AE class\n",
    "- Creating functions to select anchors at random and comput relative coordinates\n",
    "- Running tests and plotting\n",
    "- Making sure that we can create embeddings with new seeds while maintaining the same anchors\n",
    "\n",
    "#### Results\n",
    "<img src=\"experiments/initial_AE_testing/2D_latent_encodings.png\" alt=\"2D Latent Encodings\" width=\"30%\">\n",
    "\n",
    "first plot of relative representation. made from a 2D latent space using 2 anchors\n",
    "\n",
    "<img src=\"experiments/initial_AE_testing/first_rel_rep_plot.png\" alt=\"2D Latent Encodings\" width=\"30%\">\n",
    "\n",
    "$\\textbf{Interesting observation}$: Relative representations will always create a \"hyper-ellipse\" in some n-dimensional vector space where n is equal to the number of anchors. Because you can't change one dimension without changing the others. It is easiest to visualize in 2D, but the same rule applies for higher dimensions. Maybe this is useful somehow.\n",
    "##### **Plan for next time**\n",
    "- Try making a AE with higher dimensional output and making relative representation on that\n",
    "- Experiment with new ways of choosing anchors\n",
    "- Compare absolute and relative latent spaces between different latent spaces of MNIST\n",
    "- Experiment with high-dimensional embeddings\n",
    "    - PCA for visualization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
